{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c2575b4-3048-46ab-bfa0-b4210897b732",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import random_split\n",
    "\n",
    "from torch_geometric.nn import global_mean_pool\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.data import Batch\n",
    "from torch_geometric.nn import GCNConv, VGAE\n",
    "\n",
    "import os\n",
    "import kagglehub\n",
    "from kagglehub import KaggleDatasetAdapter\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from tqdm import tqdm\n",
    "from tqdm.contrib import tmap\n",
    "from tqdm.contrib.concurrent import process_map\n",
    "\n",
    "from torchvision import transforms\n",
    "\n",
    "from concurrent.futures import ProcessPoolExecutor\n",
    "\n",
    "from lib.lib import SiameseSignatureDataset\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.metrics import roc_curve, auc, precision_recall_fscore_support\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "491be029-42f9-4fa5-aaca-fb4f2fa21eb8",
   "metadata": {},
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c07ca82-0117-4817-a678-5c6e08b1d2a5",
   "metadata": {},
   "source": [
    "## prepare data from mallapraveen/signature-matching\n",
    "## and construct it using data.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11f073c6-cfc5-4011-a96e-cd7edf19e0ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data.csv')\n",
    "\n",
    "def dataset_path():\n",
    "    path = kagglehub.dataset_download(\"mallapraveen/signature-matching\")\n",
    "    return os.path.join(path, 'custom\\\\full')\n",
    "\n",
    "def transform(**kwargs):\n",
    "    return transforms.Compose([\n",
    "        transforms.Grayscale(num_output_channels=kwargs['num_output_channels']),\n",
    "        transforms.Resize(kwargs['resize']),\n",
    "        transforms.ToTensor(),\n",
    "    ])\n",
    "    \n",
    "dataset = SiameseSignatureDataset(\n",
    "    root_dir=dataset_path(),\n",
    "    signer_folders=df,\n",
    "    transform=transform(num_output_channels=1, resize=(32, 32)\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0488d63b-2f52-4ff7-9be6-044af6c77329",
   "metadata": {},
   "source": [
    "## split the data\n",
    "### train dataset & validation dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e513319-7675-4c27-8ba5-cefe8ce09d6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_size = len(dataset)\n",
    "train_size = int(0.8 * total_size)\n",
    "val_size = total_size - train_size\n",
    "train_dataset, val_dataset = random_split(\n",
    "    dataset,\n",
    "    [train_size, val_size],\n",
    "    generator=torch.Generator().manual_seed(42)\n",
    ")\n",
    "print(f\"Dataset sizes - Train: {train_size}, Validation: {val_size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26abdce4-c402-4ed2-8cf3-2c0c645e9674",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ca0393f-4ea8-4391-9015-1eac9e2eec40",
   "metadata": {},
   "source": [
    "## load the data using dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1934d689-2e62-4ac7-9ad6-88616bed49bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=32,\n",
    "    shuffle=True,\n",
    "    num_workers=4\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=256,\n",
    "    shuffle=False,\n",
    "    num_workers=4\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb8633a8-34ee-4248-b371-56299650d3a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "next(iter(train_loader))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25f0cea4-8e89-43f3-94cd-c689f6769295",
   "metadata": {},
   "source": [
    "# Model Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb4c7de3-b340-4d6f-869d-41f83f4d2411",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GNNEncoder(torch.nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, latent_dim):\n",
    "        super(GNNEncoder, self).__init__()\n",
    "        self.conv1 = GCNConv(in_channels, hidden_channels)\n",
    "        self.conv_mu = GCNConv(hidden_channels, latent_dim)\n",
    "        self.conv_logvar = GCNConv(hidden_channels, latent_dim)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        # Step 1: Aggregate node features from neighbors\n",
    "        x = F.relu(self.conv1(x, edge_index))\n",
    "\n",
    "        # Step 2: Output mean and log variance\n",
    "        mu = self.conv_mu(x, edge_index)\n",
    "        logvar = self.conv_logvar(x, edge_index)\n",
    "\n",
    "        return mu, logvar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "684ce35a-fbc1-4ae6-b6a2-e286cacb5e3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SiameseNetwork(nn.Module):\n",
    "    def __init__(self, fe_model, latent_dim):\n",
    "        super(SiameseNetwork, self).__init__()\n",
    "        self.encoder = fe_model\n",
    "        self.embedding_dim = latent_dim\n",
    "        \n",
    "        self.projector = nn.Sequential(\n",
    "            nn.Linear(self.embedding_dim * 4, 128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(p=0.5),\n",
    "\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(p=0.5),\n",
    "\n",
    "            nn.Linear(64, 2)\n",
    "        )\n",
    "\n",
    "    def forward_once(self, x, edge_index, batch):\n",
    "        mu, _ = self.encoder(x, edge_index)\n",
    "        graph_emb = global_mean_pool(mu, batch) \n",
    "        # x = torch.flatten(x, 1)\n",
    "        # return x\n",
    "        return graph_emb\n",
    "\n",
    "    def forward(self, x1, x2,\n",
    "               edge_index1, edge_index2,\n",
    "               batch):\n",
    "        emb1 = self.forward_once(x1, edge_index1, batch)\n",
    "        emb2 = self.forward_once(x2, edge_index2, batch)\n",
    "\n",
    "        # Combine embeddings (abs difference works well for verification)\n",
    "        combined = torch.cat([\n",
    "            emb1,\n",
    "            emb2,\n",
    "            torch.abs(emb1 - emb2),\n",
    "            emb1 * emb2\n",
    "        ], dim=1)\n",
    "\n",
    "        # Predict same/forged\n",
    "        out = self.projector(combined)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da78ed92-5596-4992-85d5-28c8731a5626",
   "metadata": {},
   "source": [
    "# Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c916c85c-e942-42af-95fb-09a24f7f3827",
   "metadata": {},
   "outputs": [],
   "source": [
    "w_d = 1e-5\n",
    "epochs = 50\n",
    "learning_rate = 1e-3\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24540b2e-ac04-4280-b8fe-85536b712618",
   "metadata": {},
   "source": [
    "# Training Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9379a45f-7931-452c-974e-6ea79202ecf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "img1, _, _ = next(iter(train_loader))\n",
    "\n",
    "input_dim = img1.x.shape[1]\n",
    "hidden_dim = 64\n",
    "latent_dim = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91b65f9c-3db2-45b1-b801-d6ea5a648909",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load your trained GNN-VAE\n",
    "checkpoint = torch.load('VGAE_Model.pt', map_location=device)\n",
    "vgae = VGAE(GNNEncoder(in_channels=input_dim, hidden_channels=hidden_dim, latent_dim=latent_dim)).to(device)\n",
    "vgae.load_state_dict(checkpoint)\n",
    "vgae.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "432ec032-34a8-482c-9152-b07f5a76b674",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SiameseNetwork(vgae, latent_dim=128).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c40c3824-280f-4f7e-ab0c-a4123e2ab628",
   "metadata": {},
   "source": [
    "## train steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "396f1dfa-adad-4bc1-965f-84410cdbb9e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(model, dataloader, criterion, optimizer, device):\n",
    "    model.train()\n",
    "    total_loss, correct, total = 0.0, 0, 0\n",
    "\n",
    "    for x1, x2, label in tqdm(dataloader, desc=\"Training\", leave=False):\n",
    "        x1, x2, label = x1.to(device), x2.to(device), label.to(device)\n",
    "\n",
    "        # Forward\n",
    "        output = model(x1.x.to(device),\n",
    "                    x2.x.to(device),\n",
    "                    x1.edge_index.to(device),\n",
    "                    x2.edge_index.to(device),\n",
    "                    x1.batch)  # logits shape: [batch, 2]\n",
    "        \n",
    "        loss = criterion(output, label)\n",
    "\n",
    "        # Backprop\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Metrics\n",
    "        total_loss += loss.item() * x1.size(0)\n",
    "        preds = torch.argmax(output, dim=1)\n",
    "        correct += (preds == label).sum().item()\n",
    "        total += label.size(0)\n",
    "\n",
    "    avg_loss = total_loss / total\n",
    "    accuracy = correct / total\n",
    "    return avg_loss, accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "326e83ec-e15d-4c11-89bb-aa5897996fab",
   "metadata": {},
   "source": [
    "## validation steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "614a467f-5e31-4dc5-850d-caea7b9218c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def val_step(model, dataloader, criterion, device):\n",
    "    model.eval()\n",
    "    total_loss, correct, total = 0.0, 0, 0\n",
    "    all_labels = []\n",
    "    all_preds = []\n",
    "    all_probs = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for x1, x2, label in tqdm(dataloader, desc=\"Validating\", leave=False):\n",
    "            x1, x2, label = x1.to(device), x2.to(device), label.to(device)\n",
    "            output = model(x1.x.to(device),\n",
    "                    x2.x.to(device),\n",
    "                    x1.edge_index.to(device),\n",
    "                    x2.edge_index.to(device),\n",
    "                    x1.batch)\n",
    "\n",
    "            loss = criterion(output, label)\n",
    "            total_loss += loss.item() * x1.size(0)\n",
    "\n",
    "            probs = torch.softmax(output, dim=1)[:, 1]  # Probability of class 1 (\"genuine\")\n",
    "            preds = torch.argmax(output, dim=1)\n",
    "\n",
    "            all_labels.extend(label.cpu().numpy())\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_probs.extend(probs.cpu().numpy())\n",
    "\n",
    "            correct += (preds == label).sum().item()\n",
    "            total += label.size(0)\n",
    "\n",
    "    avg_loss = total_loss / total\n",
    "    accuracy = correct / total\n",
    "    return avg_loss, accuracy, np.array(all_labels), np.array(all_preds), np.array(all_probs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14ad49e3-508d-43ff-8ed4-3018c7ab032c",
   "metadata": {},
   "source": [
    "# Training Phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c007e001-891d-4262-8fc2-bfad52e0dfc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = SummaryWriter(log_dir=\"runs/siamese_signature_experiment\")\n",
    "\n",
    "patience = 10\n",
    "best_auc = 0.0\n",
    "best_val_loss = float('inf')  # start with infinity\n",
    "wait = 0  # counter for early stopping\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    train_loss, train_acc = train_step(model, train_loader, criterion, optimizer, device)\n",
    "    val_loss, val_acc, y_true, y_pred, y_prob = val_step(model, val_loader, criterion, device)\n",
    "\n",
    "    # --- Confusion Matrix ---\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "    fig_cm, ax_cm = plt.subplots(figsize=(4, 4))\n",
    "    disp.plot(ax=ax_cm, cmap=\"Blues\", colorbar=False)\n",
    "    writer.add_figure(\"ConfusionMatrix/val\", fig_cm, global_step=epoch)\n",
    "    plt.close(fig_cm)\n",
    "\n",
    "    # --- ROC Curve and AUC ---\n",
    "    fpr, tpr, _ = roc_curve(y_true, y_prob)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    fig_roc, ax_roc = plt.subplots()\n",
    "    ax_roc.plot(fpr, tpr, color='blue', lw=2, label=f\"AUC = {roc_auc:.3f}\")\n",
    "    ax_roc.plot([0, 1], [0, 1], color='gray', linestyle='--')\n",
    "    ax_roc.set_xlabel(\"False Positive Rate\")\n",
    "    ax_roc.set_ylabel(\"True Positive Rate\")\n",
    "    ax_roc.legend(loc=\"lower right\")\n",
    "    writer.add_figure(\"ROC/val\", fig_roc, global_step=epoch)\n",
    "    plt.close(fig_roc)\n",
    "\n",
    "    # --- Precision, Recall, F1 ---\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(\n",
    "        y_true, y_pred, average=\"binary\"\n",
    "    )\n",
    "\n",
    "    # Log scalar metrics\n",
    "    writer.add_scalar(\"Loss/train\", train_loss, epoch)\n",
    "    writer.add_scalar(\"Loss/val\", val_loss, epoch)\n",
    "    writer.add_scalar(\"Accuracy/train\", train_acc, epoch)\n",
    "    writer.add_scalar(\"Accuracy/val\", val_acc, epoch)\n",
    "    writer.add_scalar(\"AUC/val\", roc_auc, epoch)\n",
    "    writer.add_scalar(\"Precision/val\", precision, epoch)\n",
    "    writer.add_scalar(\"Recall/val\", recall, epoch)\n",
    "    writer.add_scalar(\"F1/val\", f1, epoch)\n",
    "\n",
    "    print(f\"Epoch [{epoch+1}/{epochs}] \"\n",
    "          f\"Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.4f} \"\n",
    "          f\"| Val Loss: {val_loss:.4f} | Val Acc: {val_acc:.4f} \"\n",
    "          f\"| AUC: {roc_auc:.4f} | F1: {f1:.4f}\")\n",
    "\n",
    "    # --- Save best model by AUC ---\n",
    "    if roc_auc > best_auc:\n",
    "        best_auc = roc_auc\n",
    "        torch.save(model.state_dict(), \"best_siamese_signature.pth\")\n",
    "\n",
    "    # --- Early stopping based on validation loss ---\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        wait = 0  # reset counter if improved\n",
    "        torch.save(model.state_dict(), os.path.join(writer.log_dir, \"best_vgae_model.pth\"))\n",
    "    else:\n",
    "        wait += 1\n",
    "        if wait >= patience:\n",
    "            print(f\"⏹️ Early stopping triggered at epoch {epoch+1}!\")\n",
    "            break\n",
    "\n",
    "writer.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cda2868-4190-45a9-90d8-20c21aded63c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eb01c51-c975-432d-81ec-b4fed0b3fd75",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
