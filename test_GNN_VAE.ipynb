{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "be92520f-f6d1-428a-a792-ac1dec3b615e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch_geometric.nn import GCNConv, VGAE\n",
    "from torch_geometric.loader import DataLoader\n",
    "\n",
    "from torchvision import transforms\n",
    "\n",
    "from lib.lib import SignatureDataset, image_to_graph\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dfa8f75b-4b8a-432b-85a6-a0e801121ac7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 4 signature images (genuine + forged)\n"
     ]
    }
   ],
   "source": [
    "def transform(**kwargs):\n",
    "    return transforms.Compose([\n",
    "        transforms.Grayscale(num_output_channels=kwargs['num_output_channels']),\n",
    "        transforms.Resize(kwargs['resize']),\n",
    "        transforms.ToTensor(),\n",
    "    ])\n",
    "\n",
    "dataset = SignatureDataset(\n",
    "    root_dir=\"test_image\",\n",
    "    transform=transform(num_output_channels=1, resize=(150, 150))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7f0f76c8-a1e8-4746-8061-47cd6b3079df",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GNNEncoder(torch.nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, latent_dim):\n",
    "        super(GNNEncoder, self).__init__()\n",
    "        self.conv1 = GCNConv(in_channels, hidden_channels)\n",
    "        self.conv_mu = GCNConv(hidden_channels, latent_dim)\n",
    "        self.conv_logvar = GCNConv(hidden_channels, latent_dim)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        # Step 1: Aggregate node features from neighbors\n",
    "        x = F.relu(self.conv1(x, edge_index))\n",
    "\n",
    "        # Step 2: Output mean and log variance\n",
    "        mu = self.conv_mu(x, edge_index)\n",
    "        logvar = self.conv_logvar(x, edge_index)\n",
    "\n",
    "        return mu, logvar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9e032438-b38d-4530-9f54-7e758334756f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train graphs: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "test_graph = []\n",
    "\n",
    "# Convert training dataset\n",
    "for t in tqdm(dataset, desc=\"Train Graphs\", leave=False):\n",
    "    t_graph = image_to_graph(t)\n",
    "    test_graph.append(t_graph)\n",
    "\n",
    "print(\"Train graphs:\", len(test_graph))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1793f36e-f78b-4f47-972b-32d78a25bb3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataBatch(x=[3072, 3], edge_index=[2, 11904], batch=[3072], ptr=[4])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_loader = DataLoader(\n",
    "    test_graph,\n",
    "    batch_size=3,        # Process 32 graphs at once\n",
    "    shuffle=True,         # Shuffle for training\n",
    "    num_workers=0,        # 0 for debugging, 2-4 for faster loading\n",
    "    # pin_memory=True \n",
    ")\n",
    "\n",
    "next(iter(test_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "39e9b15d-1eab-4f5c-a126-62cbe6ca20da",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = next(iter(test_graph)).x.shape[1]\n",
    "hidden_dim = 64\n",
    "latent_dim = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e5661908-892b-4dbb-9627-562ddc1c78f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VGAE(\n",
       "  (encoder): GNNEncoder(\n",
       "    (conv1): GCNConv(3, 64)\n",
       "    (conv_mu): GCNConv(64, 128)\n",
       "    (conv_logvar): GCNConv(64, 128)\n",
       "  )\n",
       "  (decoder): InnerProductDecoder()\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = VGAE(GNNEncoder(in_channels=input_dim, hidden_channels=hidden_dim, latent_dim=latent_dim))\n",
    "model.load_state_dict(torch.load('VGAE_Model.pt', weights_only=True))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a7450035-cf3b-4a2e-a12f-ae69a2b213b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(x=[1024, 3], edge_index=[2, 3968])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = test_graph[3]\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "80f950da-051b-4469-804c-246b04240f02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.9273e-02, -2.4731e-01,  5.1219e-01,  ...,  4.7546e-01,\n",
       "         -6.1950e-01,  3.1648e-01],\n",
       "        [-1.0733e-02, -2.6901e-01,  5.3688e-01,  ...,  5.0413e-01,\n",
       "         -6.6039e-01,  3.3467e-01],\n",
       "        [-4.5014e-04, -2.6558e-01,  5.1661e-01,  ...,  4.8351e-01,\n",
       "         -6.2979e-01,  3.1698e-01],\n",
       "        ...,\n",
       "        [-5.9373e-01, -1.6010e-01,  7.3992e-01,  ...,  5.1322e-01,\n",
       "          4.7961e-01,  1.1018e-01],\n",
       "        [-6.0516e-01, -1.7531e-01,  7.6734e-01,  ...,  5.3392e-01,\n",
       "          4.9888e-01,  1.1160e-01],\n",
       "        [-5.4051e-01, -1.7229e-01,  7.1834e-01,  ...,  5.0166e-01,\n",
       "          4.2534e-01,  1.1147e-01]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    z = model.encode(data.x, data.edge_index)\n",
    "\n",
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d1ee439-bb44-4819-97f9-14265a6b5775",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
