{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "be92520f-f6d1-428a-a792-ac1dec3b615e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch_geometric.nn import GCNConv, VGAE\n",
    "from torch_geometric.loader import DataLoader\n",
    "\n",
    "from torchvision import transforms\n",
    "\n",
    "from lib.lib import SignatureDataset, image_to_graph\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "dfa8f75b-4b8a-432b-85a6-a0e801121ac7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 3 signature images (genuine + forged)\n"
     ]
    }
   ],
   "source": [
    "def transform(**kwargs):\n",
    "    return transforms.Compose([\n",
    "        transforms.Grayscale(num_output_channels=kwargs['num_output_channels']),\n",
    "        transforms.Resize(kwargs['resize']),\n",
    "        transforms.ToTensor(),\n",
    "    ])\n",
    "\n",
    "dataset = SignatureDataset(\n",
    "    root_dir=\"test_image\",\n",
    "    transform=transform(num_output_channels=1, resize=(150, 150))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "7f0f76c8-a1e8-4746-8061-47cd6b3079df",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GNNEncoder(torch.nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, latent_dim):\n",
    "        super(GNNEncoder, self).__init__()\n",
    "        self.conv1 = GCNConv(in_channels, hidden_channels)\n",
    "        self.conv_mu = GCNConv(hidden_channels, latent_dim)\n",
    "        self.conv_logvar = GCNConv(hidden_channels, latent_dim)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        # Step 1: Aggregate node features from neighbors\n",
    "        x = F.relu(self.conv1(x, edge_index))\n",
    "\n",
    "        # Step 2: Output mean and log variance\n",
    "        mu = self.conv_mu(x, edge_index)\n",
    "        logvar = self.conv_logvar(x, edge_index)\n",
    "\n",
    "        return mu, logvar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "9e032438-b38d-4530-9f54-7e758334756f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train graphs: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "test_graph = []\n",
    "\n",
    "# Convert training dataset\n",
    "for t in tqdm(dataset, desc=\"Train Graphs\", leave=False):\n",
    "    t_graph = image_to_graph(t)\n",
    "    test_graph.append(t_graph)\n",
    "\n",
    "print(\"Train graphs:\", len(test_graph))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "1793f36e-f78b-4f47-972b-32d78a25bb3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataBatch(x=[3072, 3], edge_index=[2, 11904], batch=[3072], ptr=[4])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_loader = DataLoader(\n",
    "    test_graph,\n",
    "    batch_size=3,        # Process 32 graphs at once\n",
    "    shuffle=True,         # Shuffle for training\n",
    "    num_workers=0,        # 0 for debugging, 2-4 for faster loading\n",
    "    # pin_memory=True \n",
    ")\n",
    "\n",
    "next(iter(test_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "39e9b15d-1eab-4f5c-a126-62cbe6ca20da",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = next(iter(test_graph)).x.shape[1]\n",
    "hidden_dim = 64\n",
    "latent_dim = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "e5661908-892b-4dbb-9627-562ddc1c78f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VGAE(\n",
       "  (encoder): GNNEncoder(\n",
       "    (conv1): GCNConv(3, 64)\n",
       "    (conv_mu): GCNConv(64, 128)\n",
       "    (conv_logvar): GCNConv(64, 128)\n",
       "  )\n",
       "  (decoder): InnerProductDecoder()\n",
       ")"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = VGAE(GNNEncoder(in_channels=input_dim, hidden_channels=hidden_dim, latent_dim=latent_dim))\n",
    "model.load_state_dict(torch.load('VGAE_Model.pt', weights_only=True))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "a7450035-cf3b-4a2e-a12f-ae69a2b213b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(x=[1024, 3], edge_index=[2, 3968])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = test_graph[0]\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "80f950da-051b-4469-804c-246b04240f02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0464,  0.0318,  0.0354,  ..., -0.1222,  0.0228,  0.0388],\n",
       "        [ 0.0478,  0.0379,  0.0339,  ..., -0.1361,  0.0277,  0.0396],\n",
       "        [ 0.0499,  0.0502,  0.0263,  ..., -0.1482,  0.0333,  0.0392],\n",
       "        ...,\n",
       "        [-0.0979, -0.1036, -0.3266,  ...,  0.1507,  0.1983,  0.2764],\n",
       "        [-0.1074, -0.1091, -0.3531,  ...,  0.1390,  0.2204,  0.2983],\n",
       "        [-0.0948, -0.0944, -0.3250,  ...,  0.1040,  0.2092,  0.2797]])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    z = model.encode(data.x, data.edge_index)\n",
    "\n",
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d1ee439-bb44-4819-97f9-14265a6b5775",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
